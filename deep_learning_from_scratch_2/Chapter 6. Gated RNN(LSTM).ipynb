{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5장에서 본 RNN은 순환경로를 포함하며 과거의 정보를 기억할 수 있었다.\n",
    "## 구조가 단순하고 구현도 쉽지만 성능이 좋지 못하다.\n",
    "## 시계열 데이터에서 시간적으로 멀리 떨어진, 장기(Long Term)의존 관계를 잘 학습하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 요즘에는 단순 RNN 대신 LSTM, GRU이 주로 쓰인다.\n",
    "## LSTM, GRU에는 게이트(gate)라는 구조가 더해져 있는데, 이 게이트 덕분에 시계열 데이터의 장기 의존 관계를 학습할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RNN의 문제점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN은 장기 의존 관계 학습이 어려운데, 그 이유는 BPTT에서 기울기 소실 또는 기울기 폭발이 일어나기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 소실과 기울기 폭발의 원인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 길이가 T인 시계열 데이터를 가정하여 T번째 정답 레이블로부터 전해지는 기울기가 어떻게 변하는지 보자.\n",
    "## RNN 계층에서 시간방향 기울기 전파에만 주목해보자\n",
    "## 시간 방향 기울기에 주목하면 역전파로 전해지는 기울기는 차례로 'tanh', '+', 'MatMul(행렬 곱)' 연산을 통과한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## '+'의 역전파는 그대로 흘러보낼 뿐이므로 기울기 변화가 없다.\n",
    "## 'tanh'의 경우 미분하면 1 - tanh**2 이다. 그래프를 보면 y값이 0과 1사이이고 x가 0으로부터 멀어질수록 값이 작아진다.\n",
    "## 따라서 역전파에서 기울기가 tanh 노드를 지날 때마다 값은 점점 작아진다.\n",
    "## ReLU를 사용하면 기울기 소실 문제를 줄일 수 있다. 입력 x가 0이상이면 상류의 기울기를 그대로 보내기 때문이다.\n",
    "\n",
    "## 'MatMul' 노드에서 상류로부터 dh라는 기울기가 흘러온다고 하면, 통과 후 dhW(h).T가 된다. 그리고 같은 계산을 시계열 데이터\n",
    "## 시간 크기만큼 반복한다. 여기서 주목할 점은 매번 똑같은 가중치 W(h)가 사용된다는 것이다.\n",
    "## 그러면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4684068094579303, 3.3357049741610365, 4.783279375373182, 6.279587332087612, 8.080776465019053, 10.251163032292936, 12.936063506609896, 16.276861327786712, 20.45482961834598, 25.688972842084684, 32.25315718048336, 40.48895641683869, 50.8244073070191, 63.79612654485427, 80.07737014308985, 100.5129892205125, 126.16331847536823, 158.35920648258823, 198.7710796761195, 249.495615421267]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2\n",
    "H = 3\n",
    "T = 20\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3) # 재현할 수 있도록 난수의 시드 고정\n",
    "Wh = np.random.randn(H, H)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):  ## matmul 노드 수(T)만큼 dh 갱신\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N \n",
    "    norm_list.append(norm)  ## 각 단계에서 dh의 크기(norm)을 구해 norm_list에 저장\n",
    "    \n",
    "print(norm_list)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결과를 보면 시간에 비례해 지수적으로 기울기가 커지는 것을 알 수 있다.\n",
    "## 이것이 바로 기울기 폭발(gradient exploding)이다.\n",
    "## 기울기 폭발이 이러나면 오버플로를 일으켜 NaN(Not a Number)값을 발생시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2342034047289652, 0.8339262435402591, 0.5979099219216477, 0.39247420825547574, 0.2525242645318454, 0.16017442237957713, 0.10106299614538981, 0.06358148956166684, 0.03995083909833199, 0.025086887541098325, 0.015748611904532892, 0.009884999125204758, 0.006204151282595105, 0.003893806551809953, 0.002443767399386287, 0.0015337065005571365, 0.0009625497320203265, 0.0006040924319556741, 0.00037912574706291106, 0.00023793756048323344]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Wh의 초깃값을 변경한 뒤 다시 실험을 해보자\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2\n",
    "H = 3\n",
    "T = 20\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3) # 재현할 수 있도록 난수의 시드 고정\n",
    "# Wh = np.random.randn(H, H)\n",
    "Wh = np.random.randn(H, H) * 0.5\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):  ## matmul 노드 수(T)만큼 dh 갱신\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N \n",
    "    norm_list.append(norm)  ## 각 단계에서 dh의 크기(norm)을 구해 norm_list에 저장\n",
    "    \n",
    "print(norm_list)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이번에는 지수적으로 감소한다.\n",
    "## 이것이 기울기 소실(gradient vanishing)이다. \n",
    "## 기울기가 계속 작아지다가 매개변수가 더 이상 갱신되지 않게 되므로 학습이 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이런 지수적인 기울기 변화는 행렬 Wh를 T번 반복해서 곱했기 때문이다. \n",
    "## 스칼라에서는 1보다 크면 증가, 1보다 작으면 감소한다.\n",
    "## 행렬의 경우 특잇값(데이터가 얼마나 퍼져 있는지)이 척도가 된다.\n",
    "## 특잇값 중 최댓값이 1보다 큰지 여부를 보면 기울기가 어떻게 변할 지 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결국 RNN 신경망에서 'tanh'와 'MatMul' 노드로 인해 기울기 소실과 폭발 문제가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 폭발 대책"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기울기 폭발 대책으로는 전통적인 기법이 있다. \n",
    "## 바로 기울기 클리핑(gradients clipping)이라는 기법이다.\n",
    "\n",
    "## 기울기 크기(norm)이 특정 값(threshold)를 초과하면 기울기를 갱신한다. g = (threshold / norm(g)) * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [9.7795241  5.02751048 8.29001078 0.74037796 4.78915452 0.6227948\n",
      " 8.84241431 4.45810179 0.68549918]\n",
      "after: [2.24156114 1.15235384 1.90015034 0.16970176 1.09772036 0.14275057\n",
      " 2.02676655 1.02183988 0.15712302]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "\n",
    "print('before:', dW1.flatten())\n",
    "clip_grads(grads, max_norm)\n",
    "print('after:', dW1.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 기울기 소실과 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM의 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM 계층의 인터페이스에는 c라는 경로가 있다\n",
    "## c를 기억 셀(memory cell)이라 하며, LSTM 전용 기억 메커니즘이다.\n",
    "## 기억 셀의 특징은 LSTM 계층 내에서만(같은 층에서만) 주고받는다는 것이다.\n",
    "## 반면, 은닉상태 h는 RNN과 마찬가지로 다른 층으로 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 계층 조립하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM에는 기억 셀 C(t)가 있다. 이 기억 셀에는 시각 t에서의 LSTM의 기억이 저장돼 있는데\n",
    "## 과거로부터 시각 t까지 필요한 모든 정보가 저장돼 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기억 셀 c(t)는 3개의 입력(c(t-1), h(t-1), x(t))으로부터 '어떤 계산'을 수행하여 구할 수 있다. \n",
    "## 여기서 핵심은 갱신된 c(t)를 사용해 은닉 상태 h(t)를 계산한다는 것이다. h(t) = tanh(c(t))\n",
    "## 기억 셀 c(t)와 은닉 상태 h(t)의 원소 수는 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM에서 사용하는 게이트는 '열기/닫기' 뿐 아니라 어느 정도 게이트를 열지 정도 또한 조절할 수 있다.\n",
    "## 게이트의 열림 상태는 0 ~ 1 사이의 실수로 나타난다.\n",
    "## 여기서 중요한 것은 게이트를 얼마나 열까라는 것도 데이터로부터 학습한다는 것이다.\n",
    "## 게이트는 게이트 열림 상태를 제어하기 위해 전용 가중치 매개변수를 이용한다. 게이트 열림상태를 구할 때는 시그모이드 함수를 \n",
    "## 사용하는데, 시그모이드 함수 출력이 마침 0 ~ 1사이 실수이기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output 게이트의 열림 상태는 입력x(t)와 이전 상태h(t-1)로부터 구한다.\n",
    "## o = sigmoid(x(t)W(x) + h(t-1)W(h) + b)\n",
    "## h(t) = o * tanh(c(t)) --- 여기서 곱은 원소별 곱이며, 하다마르 곱(Hadamard Product)이라고도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tanh의 출력은 -1.0 ~ 1.0의 실수이다. 이 수치를 그 안에 인코딩된 '정보'의 정도를 나타낸다고 볼 수 있다.\n",
    "## sigmoid 출력은 0 ~ 1의 실수이며, 데이터를 얼마나 통과시킬지를 정하는 비율을 뜻한다.\n",
    "## 따라서 게이트에서는 sigmoid가 실질적인 정보를 지니는 데이터에는 tanh함수가 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forget 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## c(t-1)의 기억 중에서 불필요한 정보를 제거하는 역할을 한다.\n",
    "## f = sigmoid(x(t)W(x) + h(t-1)W(h) + b)\n",
    "## c(t) = f * c(t-1) --- Hadamard product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 기억 셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forget게이트를 거치면서 이전 시각의 기억 셀로부터 불필요한 기억을 없앴다.\n",
    "## 그 다음 바로 현재 상태에서 새로 기억해야 할 정보를 기억 셀에 추가해야 한다.\n",
    "## g = tanh(x(t)W(x) + h(t-1)W(h) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (f * c(t-1))+ g = c(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 게이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 마지막으로 g에 게이트를 하나 추가한다.\n",
    "## input 게이트는 g의 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단한다.\n",
    "## 새로 추가되는 정보를 적절히 취사선택하는 것이 이 게이트의 역할이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## i = sigmoid(x(t)W(x) + h(t-1)W(h) + b)\n",
    "\n",
    "## (f * c(t-1)) + (g * i) = c(t)\n",
    "## h(t) = o * tanh(c(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 기울기의 흐름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기억 셀 c의 역전파를 주목하면 기울기 소실을 없애주는 원리를 알 수 있다.\n",
    "## 기억 셀의 역전파에는 '+'와 'x'노드만을 지나게 된다. \n",
    "## '+'노드는 기울기를 그대로 흘릴 뿐이므로 기울기 변화가 없다.\n",
    "## 'x'노드는 RNN에서처럼 행렬곱이 아니라 원소별 곱(아다마르 곱)이고, 매 시각 다른 게이트 값을 이용해 원소별 곱을 한다.\n",
    "## 매번 새로운 게이트 값을 이용하므로 곱셈의 효과가 누적되지 않아 기울기 소실이 일어나지 않는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'x'노드의 계산은 forget 게이트가 제어한다. \n",
    "## forget 게이트가 중요하지 않다고 판단한 기억 셀의 원소는 기울기가 작아지고\n",
    "## 중요하다고 판단한 원소는 약화되지 않은 채 전해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최초의 한 단계만 처리하는 LSTM 클래스를 구현한 다음 이어서 T개의 단계를 한 번에 처리하는 Time LSTM 클래스를 구현해보자\n",
    "\n",
    "## f = sigmoid(x(t) * W(x)_f + h(t-1) * W(h)_f + b_f)\n",
    "## g = tanh(x(t) * W(x)_g + h(t-1) * w(h)_g + b_g)\n",
    "## i = sigmoid(x(t) * W(x)_i + h(t-1) * W(h)_i + b_i)\n",
    "## o = sigmoid(x(t) * W(x)_o + h(t-1) * W(h)_o + b_o)\n",
    "## c(t) = (f * c(t-1)) + (g * i)\n",
    "## h(t) = o * tanh(c(t))\n",
    "\n",
    "## LSTM에서 수행하는 계산이다.\n",
    "## 여기서 주목할 부분은 네 수식에 포함된 아핀 변환(xw(x) + hw(h) + b)이다. \n",
    "## 각 식의 가중치를 모아 4개의 식을 단 한 번의 아핀 변환으로 계산할 수 있다.\n",
    "## x(t)*[W(x)_f, W(x)_g, W(x)_i, W(x)_o] + h(t-1)*[W(h)_f, W(h)_g, W(h)_i, W(h)_o] + [b_f, b_g, b_i, b_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원래 총 4번의 계산을 한 번으로 마칠 수 있다.\n",
    "## 행렬 라이브러리는 큰 행렬을 한 번에 계산할 때가 훨씬 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b): ## 4개분의 가중치와 편향이 담겨 있다.\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None ## 순전파 때 중간 결과를 보관했다가 역전파 계산에 사용하려는 용도\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful = False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype = 'f')\n",
    "        \n",
    "        if not self.stateful or self.h is None: ## stateful = True, self.h = False 일때만 참이다.\n",
    "            self.h = np.zeros((N, H), dtype = 'f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype = 'f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params) # T회 반복되는 LSTM에 리스트의 인수들을 추출하여 LSTM 클래스의 __init__() 메서드에 전달한다.\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype = 'f')\n",
    "        dh, dc = 0, 0\n",
    "        \n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        \n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "        \n",
    "    def set_state(self, h, c = None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LSTM을 사용한 언어모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 앞 장에서 구현한 언어 모델과의 차이점은 LSTM을 사용한다는 점뿐이다.\n",
    "## 앞의 SimpleRnnlm 클래스와 다르게 여기서 구현할 Rnnlm 클래스는 Time RNN 대신 Time LSTM 계층을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이제 이 언어 모델을 사용해 PTB 데이터셋을 학습해보자.\n",
    "## 이번에는 PTB 데이터셋의 훈련 데이터 전부를 사용해 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10000.59\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 7[s] | 퍼플렉서티 2908.31\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 14[s] | 퍼플렉서티 1228.75\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 21[s] | 퍼플렉서티 1009.63\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 28[s] | 퍼플렉서티 793.77\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 35[s] | 퍼플렉서티 635.68\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 42[s] | 퍼플렉서티 641.66\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 49[s] | 퍼플렉서티 605.09\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 56[s] | 퍼플렉서티 564.05\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 63[s] | 퍼플렉서티 595.88\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 70[s] | 퍼플렉서티 505.81\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 77[s] | 퍼플렉서티 499.37\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 83[s] | 퍼플렉서티 450.64\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 90[s] | 퍼플렉서티 464.40\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 97[s] | 퍼플렉서티 443.63\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 104[s] | 퍼플렉서티 390.62\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 111[s] | 퍼플렉서티 350.07\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 118[s] | 퍼플렉서티 403.87\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 125[s] | 퍼플렉서티 404.58\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 132[s] | 퍼플렉서티 337.58\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 139[s] | 퍼플렉서티 350.53\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 146[s] | 퍼플렉서티 345.14\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 153[s] | 퍼플렉서티 332.98\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 160[s] | 퍼플렉서티 320.60\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 167[s] | 퍼플렉서티 304.30\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 173[s] | 퍼플렉서티 315.15\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 180[s] | 퍼플렉서티 300.88\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 187[s] | 퍼플렉서티 318.94\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 194[s] | 퍼플렉서티 283.68\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 201[s] | 퍼플렉서티 259.96\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 208[s] | 퍼플렉서티 337.93\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 215[s] | 퍼플렉서티 309.38\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 222[s] | 퍼플렉서티 282.43\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 229[s] | 퍼플렉서티 268.14\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 236[s] | 퍼플렉서티 225.01\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 243[s] | 퍼플렉서티 248.92\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 250[s] | 퍼플렉서티 258.82\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 258[s] | 퍼플렉서티 218.69\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 266[s] | 퍼플렉서티 234.22\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 275[s] | 퍼플렉서티 219.34\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 282[s] | 퍼플렉서티 242.85\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 289[s] | 퍼플렉서티 226.06\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 296[s] | 퍼플렉서티 228.31\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 303[s] | 퍼플렉서티 222.67\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 310[s] | 퍼플렉서티 205.26\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 317[s] | 퍼플렉서티 253.26\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 324[s] | 퍼플렉서티 228.89\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 331[s] | 퍼플렉서티 230.01\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 338[s] | 퍼플렉서티 246.31\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 345[s] | 퍼플렉서티 228.96\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 352[s] | 퍼플렉서티 192.35\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 359[s] | 퍼플렉서티 226.38\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 366[s] | 퍼플렉서티 208.07\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 373[s] | 퍼플렉서티 198.22\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 380[s] | 퍼플렉서티 167.83\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 387[s] | 퍼플렉서티 190.70\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 394[s] | 퍼플렉서티 227.07\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 401[s] | 퍼플렉서티 206.67\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 409[s] | 퍼플렉서티 199.99\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 416[s] | 퍼플렉서티 188.25\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 423[s] | 퍼플렉서티 160.80\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 431[s] | 퍼플렉서티 158.40\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 438[s] | 퍼플렉서티 185.65\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 446[s] | 퍼플렉서티 170.69\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 454[s] | 퍼플렉서티 177.49\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 461[s] | 퍼플렉서티 223.89\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 469[s] | 퍼플렉서티 210.95\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 472[s] | 퍼플렉서티 225.19\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 479[s] | 퍼플렉서티 203.30\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 487[s] | 퍼플렉서티 189.23\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 494[s] | 퍼플렉서티 176.36\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 501[s] | 퍼플렉서티 157.94\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 509[s] | 퍼플렉서티 151.70\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 516[s] | 퍼플렉서티 159.31\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 524[s] | 퍼플렉서티 175.96\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 531[s] | 퍼플렉서티 189.69\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 538[s] | 퍼플렉서티 201.51\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 546[s] | 퍼플렉서티 185.77\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 553[s] | 퍼플렉서티 182.75\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 561[s] | 퍼플렉서티 175.59\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 569[s] | 퍼플렉서티 185.14\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 576[s] | 퍼플렉서티 183.68\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 584[s] | 퍼플렉서티 166.13\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 591[s] | 퍼플렉서티 136.34\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 598[s] | 퍼플렉서티 170.81\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 605[s] | 퍼플렉서티 196.16\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 613[s] | 퍼플렉서티 152.48\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 620[s] | 퍼플렉서티 167.53\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 628[s] | 퍼플렉서티 153.90\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 635[s] | 퍼플렉서티 162.98\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 642[s] | 퍼플렉서티 156.03\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 650[s] | 퍼플렉서티 154.82\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 657[s] | 퍼플렉서티 169.60\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 665[s] | 퍼플렉서티 173.58\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 673[s] | 퍼플렉서티 173.19\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 680[s] | 퍼플렉서티 153.78\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 687[s] | 퍼플렉서티 137.08\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 694[s] | 퍼플렉서티 188.45\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 701[s] | 퍼플렉서티 180.59\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 709[s] | 퍼플렉서티 163.50\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 716[s] | 퍼플렉서티 153.91\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 724[s] | 퍼플렉서티 127.31\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 731[s] | 퍼플렉서티 149.74\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 739[s] | 퍼플렉서티 157.79\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 747[s] | 퍼플렉서티 131.54\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 754[s] | 퍼플렉서티 129.46\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 761[s] | 퍼플렉서티 134.63\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 769[s] | 퍼플렉서티 146.18\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 777[s] | 퍼플렉서티 141.67\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 784[s] | 퍼플렉서티 143.37\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 792[s] | 퍼플렉서티 146.25\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 800[s] | 퍼플렉서티 128.57\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 807[s] | 퍼플렉서티 164.95\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 815[s] | 퍼플렉서티 145.87\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 822[s] | 퍼플렉서티 154.26\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 830[s] | 퍼플렉서티 162.56\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 837[s] | 퍼플렉서티 151.08\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 845[s] | 퍼플렉서티 131.09\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 853[s] | 퍼플렉서티 155.17\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 860[s] | 퍼플렉서티 142.57\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 868[s] | 퍼플렉서티 127.58\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 875[s] | 퍼플렉서티 110.11\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 882[s] | 퍼플렉서티 118.51\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 890[s] | 퍼플렉서티 152.46\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 898[s] | 퍼플렉서티 138.99\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 905[s] | 퍼플렉서티 132.56\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 912[s] | 퍼플렉서티 133.20\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 919[s] | 퍼플렉서티 110.77\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 926[s] | 퍼플렉서티 108.87\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 933[s] | 퍼플렉서티 129.27\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 940[s] | 퍼플렉서티 122.35\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 948[s] | 퍼플렉서티 121.17\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 955[s] | 퍼플렉서티 157.21\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 962[s] | 퍼플렉서티 152.05\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 965[s] | 퍼플렉서티 161.64\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 973[s] | 퍼플렉서티 142.68\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 980[s] | 퍼플렉서티 134.74\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 988[s] | 퍼플렉서티 127.36\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 995[s] | 퍼플렉서티 114.71\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 1003[s] | 퍼플렉서티 104.72\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 1010[s] | 퍼플렉서티 115.97\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 1018[s] | 퍼플렉서티 125.42\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 1026[s] | 퍼플렉서티 140.97\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 1033[s] | 퍼플렉서티 151.15\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 1040[s] | 퍼플렉서티 141.83\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 1048[s] | 퍼플렉서티 139.60\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 1055[s] | 퍼플렉서티 131.73\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 1063[s] | 퍼플렉서티 137.97\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 1070[s] | 퍼플렉서티 140.76\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 1078[s] | 퍼플렉서티 122.72\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 1085[s] | 퍼플렉서티 101.38\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 1093[s] | 퍼플렉서티 123.30\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 1100[s] | 퍼플렉서티 150.79\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 1107[s] | 퍼플렉서티 112.89\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 1115[s] | 퍼플렉서티 129.34\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 1122[s] | 퍼플렉서티 112.91\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 1129[s] | 퍼플렉서티 124.07\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 1136[s] | 퍼플렉서티 117.40\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 1144[s] | 퍼플렉서티 118.23\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 1152[s] | 퍼플렉서티 128.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 521 / 1327 | 시간 1159[s] | 퍼플렉서티 137.35\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 1167[s] | 퍼플렉서티 136.23\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 1174[s] | 퍼플렉서티 117.43\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 1182[s] | 퍼플렉서티 103.12\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 1190[s] | 퍼플렉서티 145.83\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 1197[s] | 퍼플렉서티 140.79\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 1205[s] | 퍼플렉서티 126.73\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 1212[s] | 퍼플렉서티 120.88\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 1220[s] | 퍼플렉서티 98.76\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 1227[s] | 퍼플렉서티 117.20\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 1235[s] | 퍼플렉서티 124.96\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 1242[s] | 퍼플렉서티 106.44\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 1250[s] | 퍼플렉서티 101.71\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 1257[s] | 퍼플렉서티 103.90\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 1264[s] | 퍼플렉서티 114.34\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 1271[s] | 퍼플렉서티 115.53\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 1278[s] | 퍼플렉서티 113.17\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 1286[s] | 퍼플렉서티 120.21\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 1294[s] | 퍼플렉서티 104.53\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 1301[s] | 퍼플렉서티 131.09\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 1308[s] | 퍼플렉서티 118.30\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 1315[s] | 퍼플렉서티 127.21\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 1322[s] | 퍼플렉서티 131.44\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 1330[s] | 퍼플렉서티 122.37\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 1337[s] | 퍼플렉서티 109.21\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 1345[s] | 퍼플렉서티 127.71\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 1352[s] | 퍼플렉서티 117.45\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 1360[s] | 퍼플렉서티 101.92\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 1367[s] | 퍼플렉서티 87.80\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 1374[s] | 퍼플렉서티 93.42\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 1381[s] | 퍼플렉서티 121.81\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 1388[s] | 퍼플렉서티 112.35\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 1395[s] | 퍼플렉서티 105.35\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1402[s] | 퍼플렉서티 110.74\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1409[s] | 퍼플렉서티 92.79\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1417[s] | 퍼플렉서티 88.08\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1424[s] | 퍼플렉서티 104.53\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1431[s] | 퍼플렉서티 104.16\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1438[s] | 퍼플렉서티 100.24\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1445[s] | 퍼플렉서티 128.09\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1453[s] | 퍼플렉서티 125.51\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1455[s] | 퍼플렉서티 134.43\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 1463[s] | 퍼플렉서티 122.82\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 1470[s] | 퍼플렉서티 106.54\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 1477[s] | 퍼플렉서티 107.63\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 1485[s] | 퍼플렉서티 94.11\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 1492[s] | 퍼플렉서티 85.22\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 1500[s] | 퍼플렉서티 95.25\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 1507[s] | 퍼플렉서티 104.39\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 1514[s] | 퍼플렉서티 118.28\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 1522[s] | 퍼플렉서티 129.12\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 1529[s] | 퍼플렉서티 120.83\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 1536[s] | 퍼플렉서티 120.99\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 1543[s] | 퍼플렉서티 113.49\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 1551[s] | 퍼플렉서티 113.52\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 1558[s] | 퍼플렉서티 120.47\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 1566[s] | 퍼플렉서티 103.06\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 1572[s] | 퍼플렉서티 84.01\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 1580[s] | 퍼플렉서티 99.65\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 1588[s] | 퍼플렉서티 126.75\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 1596[s] | 퍼플렉서티 96.52\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 1604[s] | 퍼플렉서티 109.87\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 1611[s] | 퍼플렉서티 92.95\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 1619[s] | 퍼플렉서티 103.02\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 1627[s] | 퍼플렉서티 99.91\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 1634[s] | 퍼플렉서티 102.16\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 1641[s] | 퍼플렉서티 107.62\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 1648[s] | 퍼플렉서티 115.62\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 1655[s] | 퍼플렉서티 113.59\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 1663[s] | 퍼플렉서티 101.84\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 1670[s] | 퍼플렉서티 86.46\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 1678[s] | 퍼플렉서티 124.38\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 1685[s] | 퍼플렉서티 120.03\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 1692[s] | 퍼플렉서티 108.21\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 1699[s] | 퍼플렉서티 102.63\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 1706[s] | 퍼플렉서티 84.73\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 1713[s] | 퍼플렉서티 101.12\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 1720[s] | 퍼플렉서티 106.46\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 1727[s] | 퍼플렉서티 94.74\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 1734[s] | 퍼플렉서티 87.91\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 1740[s] | 퍼플렉서티 86.67\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 1748[s] | 퍼플렉서티 98.12\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 1756[s] | 퍼플렉서티 102.36\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 1764[s] | 퍼플렉서티 97.77\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 1771[s] | 퍼플렉서티 104.67\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 1778[s] | 퍼플렉서티 90.84\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 1786[s] | 퍼플렉서티 115.23\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1793[s] | 퍼플렉서티 102.42\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1800[s] | 퍼플렉서티 113.78\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1808[s] | 퍼플렉서티 112.88\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1816[s] | 퍼플렉서티 106.19\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1824[s] | 퍼플렉서티 96.99\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1831[s] | 퍼플렉서티 112.07\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1838[s] | 퍼플렉서티 104.01\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1845[s] | 퍼플렉서티 87.83\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1852[s] | 퍼플렉서티 77.84\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1859[s] | 퍼플렉서티 77.55\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1865[s] | 퍼플렉서티 103.94\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1872[s] | 퍼플렉서티 99.14\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1879[s] | 퍼플렉서티 90.99\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1886[s] | 퍼플렉서티 95.91\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1893[s] | 퍼플렉서티 83.10\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1900[s] | 퍼플렉서티 74.90\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1907[s] | 퍼플렉서티 91.00\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1914[s] | 퍼플렉서티 92.79\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1921[s] | 퍼플렉서티 88.90\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1928[s] | 퍼플렉서티 109.75\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1935[s] | 퍼플렉서티 109.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  135.08001375233533\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from ch06.rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 매 20번째 반복의 퍼플렉서티 값이 출려되었다.\n",
    "## 그림에서 첫 번째 퍼플렉서티의 값이 10000.59인데, 이는 다음에 나올 수 있는 후보 단어 수를 10000개 정도로 좁혔다는 뜻이다.\n",
    "## 이번 데이터 셋의 어휘 수가 10000개이므로 아직 아무 것도 학습하지 않은 상태라는 뜻이다.\n",
    "\n",
    "## 이번 실험에서 총 4에폭(반복으로 환산하면 1327 * 4회)의 학습을 수행했다.\n",
    "## 퍼플렉서티가 순조롭게 낮아져서 최종적으로 100정도가 되었다.\n",
    "## 그리고 테스트 데이터로 수행한 최종 평가는 약 135이다.\n",
    "## 2017년 기준 최첨단 연구에서 PTB 데이터셋의 퍼플렉서티가 60을 밑돌고 있다.\n",
    "## 우리 모델은 아직 개선할 여지가 많다는 방증이다.\n",
    "## 다음 절에서 현재의 RNNLM을 한 층 더 개선할 계획이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. RNNLM 추가 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 계층 다층화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNNLM으로 정확한 모델을 만들고자 한다면 LSTM 계층을 깊게 쌓아 효과를 볼 수 있다.\n",
    "## 지금까지 우리는 LSTM 계층을 1층만 사용했지만 2층, 3층 식으로 여러 겹 쌓으면 언어 모델의 정확도가 향상된다.\n",
    "## 층수는 하이퍼파라미터에 관한 문제이다. \n",
    "## 데이터의 양이나 문제의 복잡도에 따라 적절하게 결정해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃에 의한 과적합 억제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM 계층을 다층화하면 시계열 데이터의 복잡한 의존 관계를 학습할 수 있을 것이라 기대할 수 있다.\n",
    "## 층을 깊게 하면 표현력이 풍부한 모델을 만들 수 있으나 종종 과적합(overfitting)을 일으킨다.\n",
    "## 불행하게도 RNN은 일반적인 피드포워드 신경망보다 쉽게 과적합을 일으킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 과적합을 억제하는 전통적인 방법은 '훈련 데이터 양 늘리기'와 '모델의 복잡도 줄이기'가 있다. \n",
    "## 그 외에는 모델의 복잡도에 페널티를 주는 '정규화(Normalization)'도 효과적이다.\n",
    "## 또 '드롭아웃(Dropout)' 방법도 있다. \n",
    "## 이번 절에서는 드롭아웃에 관해 살펴보고 적용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 드롭아웃 계층을 시계열 방향으로 삽입하는 것은 좋은 방법이 아니다.\n",
    "## 시계열 방향으로 넣으면 시간이 흐름에 따라 정보가 사라질 수 있다.\n",
    "## 흐르는 시간에 비례해 드롭아웃에 의한 노이즈가 축적되기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그렇다면 드롭아웃 계층을 깊이 방향으로 삽입하는 방법을 생각해보자\n",
    "## 이렇게 하면 시간 방향으로 아무리 진행해도 정보를 잃지 않는다.\n",
    "## 드롭아웃이 시간과는 독립적으로 깊이 방향에만 영향을 주기 때문이다.\n",
    "## 그러나 최근 연구에서 '변형된 드롭아웃'을 제안했고, 시간 방향으로 적용하는 것에 성공했다.\n",
    "## 변형 드롭아웃은 깊이 방향은 물론 시간 방향도 적용가능하기 때문에 모델 정확도를 한 층 더 향상시킬 수 있다.\n",
    "\n",
    "## 구조를 보면 같은 계층의 드롭아웃들은 같은 마스크를 공유한다.\n",
    "## 마스크(mask)란 데이터의 통과/차단을 결정하는 이진 형태의 무작위 패턴이다.\n",
    "## 같은 계층의 드롭아웃끼리 마스크를 공유함으로써 마스크가 고정된다.\n",
    "## 그 결과 정보를 잃게 되는 방법도 고정되므로, 일반적인 드롭아웃 때와 달리 정보를 지수적으로 잃게 되는 사태는 피할 수 있다.\n",
    "## 그러나 이 책에서는 일반 드롭아웃을 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 언어 모델을 개선하는 아주 간단한 트릭 중 가중치 공유(weight tying)가 있다.\n",
    "## 이는 가중치를 공유하는 효과를 준다\n",
    "## 예 : Embedding 계층과 Softmax 앞의 Affine 계층이 가중치를 공유한다.\n",
    "## 두 계층이 가중치를 공유함으로써 학습하는 매개변수 수가 크게 줄어드는 동시에 정확도도 향상된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 어휘 수가 V, LSTM 은닉 상태 차원 수가 H라고 하면\n",
    "## Embedding 계층의 가중치 형상이 V x H가 되고, Affine 계층의 가중치 형상은 H x V가 된다.\n",
    "## 가중치 공유를 적용하려면 Embedding 계층의 가중치를 전치하여 Affine 계층의 가중치로 설정하기만 하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개선된 RNNLM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 개선점 3가지 : 다층화(2층), 드롭아웃 사용(깊이방향), 가중치공유(Embedding & Affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.valid.txt ... \n",
      "Done\n",
      "| 에폭 1 |  반복 1 / 1327 | 시간 3[s] | 퍼플렉서티 9999.90\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 68[s] | 퍼플렉서티 3552.73\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 133[s] | 퍼플렉서티 1730.79\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 200[s] | 퍼플렉서티 1312.40\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 273[s] | 퍼플렉서티 1062.90\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 353[s] | 퍼플렉서티 817.14\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 422[s] | 퍼플렉서티 750.50\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 489[s] | 퍼플렉서티 743.99\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 556[s] | 퍼플렉서티 698.02\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 624[s] | 퍼플렉서티 684.90\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 691[s] | 퍼플렉서티 590.70\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 760[s] | 퍼플렉서티 564.81\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 829[s] | 퍼플렉서티 508.62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9628cdd3a895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[1;32m---> 49\u001b[1;33m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyProject\\밑바닥 2\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyProject\\밑바닥 2\\ch06\\better_rnnlm.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyProject\\밑바닥 2\\common\\time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 개선된 RNNLM 학습\n",
    "\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ==============================================\n",
    "# config.GPU = True\n",
    "# ==============================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 후 테스트 데이터로 얻은 최종 퍼플렉서티는 75정도가 된다.\n",
    "## 개선 전 135이었음을 생각하면 상당히 개선되었다고 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
