{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 지금까지 사용한 신경망은 피드포워드(feed forward)라는 유형의 신경망이다.\n",
    "## 피드포워드란 흐름이 단 방향인 신경망을 말한다.\n",
    "## 피드포워드 신경망은 구성이 단순하여 이해하기 쉽고, 많은 문제에 응용할 수 있다.\n",
    "## 그러나 이미지 같은 공간 데이터나 시계열 데이터를 잘 다루지 못한다.\n",
    "## 따라서 공간 데이터 같은 경우 CNN을, 시계열 데이터의 경우 RNN을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec을 확률 관점에서 바라보다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## w1, w2, ..., wT라는 단어열로 표현되는 말뭉치를 생각해보자.\n",
    "## 그리고 t번째 단어를 '타깃'으로 그 전후 단어(t-1번째와 t+1번째)를 '맥락'으로 취급해보자\n",
    "\n",
    "## 이때, CBOW 모델은 맥락 w(t-1)과 w(t+1)로부터 타깃 wt를 추측하는 일을 수행한다.\n",
    "\n",
    "## 그럼 w(t-1)과 w(t+1)이 주어졌을 때 타깃이 wt가 될 확률을 수식으로 나타내면\n",
    "## P(wt | w(t-1), w(t+1))이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CBOW 모델은 사후 확률을 모델링한다.\n",
    "## 이 사후 확률은 w(t-1)과 w(t+1)이 주어졌을 때 wt가 일어날 확률을 뜻한다.\n",
    "## 이것은 윈도우 크기가 1일 때의 CBOW 모델이다.\n",
    "\n",
    "## 지금까지는 맥락을 항상 좌우 대칭으로 생각해왔다. \n",
    "## 그런데 이번에는 맥락을 왼쪽 윈도우만으로 한정해보자.\n",
    "## 그러면 CBOW 모델이 출력할 확률은 P(wt | w(t-2), w(t-1))처럼 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 따라서 CBOW 모델의 손실함수를 L = -logP(wt | w(t-2), w(t-1))처럼 쓸 수 있다. -- 교차 엔트로피 오차에 의한 결과\n",
    "## CBOW 모델의 학습으로 수행하는 일은 위의 손실함수를 최소화하는 가중치를 찾는 것이다.\n",
    "## 이러한 가중치를 발견하면 CBOW 모델은 맥락으로부터 타깃을 정확히 추측할 수 있게 된다.\n",
    "\n",
    "## 그럼 CBOW 모델의 본래 목적인 '맥락으로부터 타깃을 추측하는 것'은 어디에 쓸 수 있을까?\n",
    "## 확률 P(wt | w(t-2), w(t-1))은 실용적인 쓰임이 있을까?\n",
    "## 여기서 '언어 모델'이 등장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 언어모델(Language Model)은 단어 나열에 확률을 부여한다.\n",
    "## 특정한 단어의 시퀀스에 대해서, 그 시퀀스가 일어날 가능성이 어느 정도인지를 확률로 평가하는 것이다.\n",
    "## you say goodbye라는 시퀀스에는 높은 확률을, you say good die에는 낮은 확률을 출력하는 것이 일종의 언어 모델이다.\n",
    "\n",
    "## 이 언어모델은 다양하게 응용할 수 있다. '기계 번역'과 '음성 인식'이 대표적인 예이다.\n",
    "## 또 언어 모델은 '새로운 문장을 생성하는 용도'로도 이용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 언어 모델을 수식으로 설명해보자\n",
    "\n",
    "## w1, w2, ..., w(m)이라는 m개의 단어로 된 문장을 생각해보자\n",
    "## 이때 단어가 w1, ..., w(m)이라는 순서로 출현할 확률을 P(w1, ..., w(m))으로 나타낸다.\n",
    "## 이 확률은 여러 사건이 동시에 일어날 확률이므로 동시 확률이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이 동시 확률은 사후 확률을 사용해 분해할 수 있다.\n",
    "## P(w1, ..., w(m)) = P(w(m) | w1, ..., w(m-1))P(w(m-1) | w1, ..., w(m-2)) .... P(w3 | w1, w2)P(w2 | w1)P(w1)\n",
    "##                  = Pi(t = from 1 to m)(  P(wt | w1, ..., w(t-1))  )\n",
    "\n",
    "## 동시 확률은 사후 확률의 총곱으로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기서 주목할 것은 이 사후 확률은 타깃 단어보다 왼쪽에 있는 모든 단어를 맥락으로 했을 때의 확률이라는 것이다.\n",
    "## 정리하면, 우리의 목표는 P(wt | w1, ..., w(t-1))이라는 확률을 얻는 것이다.\n",
    "## 이 확률을 계산할 수 있다면 언어 모델의 동시 확률 P(w1, ..., w(m))을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델을 언어 모델로?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CBOW 모델을 언어 모델에 적용하려면 어떻게 하면 좋을까?\n",
    "## 이는 맥락의 크기를 특정 값으로 한정하여 근사적으로 나타낼 수 있다.\n",
    "\n",
    "## 수식으로 나타내면\n",
    "## P(w1, ..., w(m)) = Pi(t = from 1 to m)( P(wt | w1, ..., w(t-1)) ) ~~= Pi(t = from 1 to m)( P(wt | w(t-2), w(t-1)) )\n",
    "## 여기에서는 맥락을 왼쪽 2개 단어로 한정한다. 그러면 근사적으로 나타낼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 맥락은 임의의 길이로 설정할 수 있다.(5나 10 등) \n",
    "## 그러나 임의 길이로 설정한다고 해도, 결국 특정 길이로 고정된다. 그래서 특정 길이보다 더 왼쪽의 단어 정보들은 무시된다.\n",
    "## Tom was watching TV in his room. Mary came into the room. Mary said hi to ( ? ).\n",
    "## 위 문제에서 문맥을 고려하면 Marry가 Tom에게 인사를 건넸다가 정답이다. \n",
    "## 정답을 구하려면 ?로부터 18번째 앞에 나오는 Tom을 기억해야한다. \n",
    "## 만약 맥락이 10개였다면 제대로 답할 수 없다\n",
    "## 맥락을 20까지 키우면 해결될까?\n",
    "## CBOW 모델에서는 맥락 안의 단어 순서가 무시된다는 한계가 있기 때문에 불가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CBOW 모델의 은닉층에서는 단어 벡터들이 더해지므로 맥락의 단어 순서는 무시된다.\n",
    "## (you, say)와 (say, you)라는 맥락을 똑같이 취급한다.\n",
    "## 이상적으로는 맥락 단어 순서도 고려한 모델이 바람직하다.\n",
    "## 이를 위해 맥락의 단어 벡터를 은닉층에서 연결하는 방식을 생각할 수 있다.\n",
    "## 그러나 연결하는 방식은 맥락의 크기에 비례해 가중치 매개변수도 늘어난다. 이는 환영할만한 현상이 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그렇다면 이 문제는 어떻게 해결할까?\n",
    "## 여기서 등장하는 것이 RNN이다.\n",
    "## RNN은 맥락이 아무리 길더라도 그 맥락의 정보를 기억하는 메커니즘을 가지고 있다.\n",
    "## 그래서 RNN을 사용하면 아무리 긴 시계열 데이터에도 대응할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RNN이란"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환하는 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 순환하기 위해서는 닫힌 경로가 필요하다.\n",
    "## 닫힌 경로가 존재해야 데이터가 순환하면서 정보가 끊임없이 갱신되게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 순환경로를 포함하는 RNN계층에는 (x0, x1, ..., x(t), ...)를 입력받는데, t는 시각을 뜻한다.\n",
    "## 또 각 시각에 입력되는 x(t)는 벡터라고 가정한다.\n",
    "## 문장을 다루는 경우를 예로 들면, 각 단어의 분산표현(단어 벡터)이 x(t)가 되며, 이 분산 표현이 순서대로 하나씩 RNN에 입력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 구조 펼치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 시각의 RNN 계층은 그 계층으로의 입력과 1개 시각 전의 RNN 계층으로부터의 출력을 입력으로 받는다.\n",
    "## 그리고 이 두 정보를 바탕으로 현 시각의 출력을 계산한다.\n",
    "## h(t) = tanh( h(t-1)*W(h) + x(t)*W(x) + b )\n",
    "## RNN 은 h라는 상태를 가지고 있으며, 위 식의 형태로 갱신된다고 해석할 수 있다.\n",
    "## 그래서 RNN 계층을 '상태를 가지는 계층' 혹은 '메모리가 있는 계층'이라고 한다.\n",
    "## 많은 문헌에서 RNN의 출력 h(t)를 은닉 상태(hidden state) 또는 은닉 상태 벡터(hidden state vector)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN 계층은 가로로 펼친 신경망으로 간주할 수 있다.\n",
    "## 다수의 RNN 구조가 가로로 펼쳐져 있지만 실제로는 이것이 하나의 계층이다.\n",
    "## 이 순환 구조를 펼친 RNN에는 오차역전파법을 적용할 수 있다.\n",
    "## 여기서의 오차역전파는 시간 방향으로 펼친 신경망의 오차역전파법이란 뜻으로\n",
    "## BPTT(backpropagation through time)라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하지만 그 전에 BPTT를 이용해 기울기를 구하려면, 매 시각 RNN 구조의 중간 데이터를 메모리에 유지해두지 않으면 안 된다.\n",
    "## 따라서 시계열 데이터가 길어짐에 따라 메모리 사용량도 증가하게 된다.\n",
    "## 또한 시간 크기가 커지면 역전파 시 기울기가 불안정해지는 것도 문제다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 큰 시계열 데이터를 취급할 때는 흔히 신경망의 연결을 적당한 길이로 끊는다.\n",
    "## 시간축 방향으로 너무 길어진 신경망을 적당한 지점에서 잘라 작은 신경망 여러 개로 만든다는 아이디어이다.\n",
    "## 그리고 잘라낸 작은 신경망에서 오차역전파를 수행한다.\n",
    "## 이것을 Truncated BPTT라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한 가지 주의할 점은 역전파의 연결만 끊어야 한다. 순전파의 연결은 그대로 유지해야 한다.\n",
    "## 역전파는 잘라낸 신경망 단위로 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 지금까지 본 신경망에서는 미니배치 학습을 수행할 때 데이터를 무작위로 선택해 입력했다.\n",
    "## 그러나 RNN에서 Truncated BPTT를 수행할 때는 데이터를 순서대로 입력해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 두 블록의 Truncated BPTT를 수행해보자\n",
    "## 먼저 첫 번째 블록에 데이터를 입력해 순전파를 진행하고, 나온 출력을 다음 블록에 전달한다.\n",
    "## 첫 번째 블록의 순전파가 끝나면 역전파를 수행한다. \n",
    "## 이런 식으로 순전파의 연결을 유지하면서 블록 단위로 오차역전파법을 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated BPTT의 미니배치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 지금까지는 미니배치 수가 1일 때에 해당한다.\n",
    "## 미니배치 학습을 수행하려면 데이터를 주는 시작 위치를 각 미니배치의 시작 위치로 옮겨줘야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 지금부터 구현해야 할 것은 가로 방향으로 성장한 신경망이다.\n",
    "## 그리고 Truncated BPTT 방식의 학습을 따른다면, 가로 크기가 일정한 일련의 신경망을 만들면 된다.\n",
    "## 길이가 T인 시계열 데이터를 받아 각 시각의 은닉 상태를 T개 출력한다.\n",
    "## 모듈화를 생각해 옆으로 성장한 신경망을 하나의 계층으로 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hs = (h0, h1, ..., h(T-1))\n",
    "## xs = (x0, x1, ..., x(T-1))\n",
    "## xs --> Time RNN --> hs\n",
    "## 순환 구조를 펼친 후의 RNN 구조들을 하나의 계층으로 간주한다. 이를 Time RNN 계층이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN 처리를 한 단계만 수행하는 클래스부터 구현해보자.\n",
    "## 여기서 우리는 데이터를 미니배치로 모아 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## h(t-1) *  W(h)  +  x(t)  *  W(x) = h(t)\n",
    "## (N, H) * (H, H) + (N, D) * (D, H) = (N, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self,dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next**2)\n",
    "        db = np.sum(dt, axis = 0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이어서 Time RNN 계층을 구현할 차례이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time RNN 계층은 T개의 RNN 계층으로 구성된다.\n",
    "## RNN 계층 T개를 연결한 신경망이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful = False): ## 앞의 계층에서 은닉 상태를 이어 받는지 유무\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None ## 여러개의 RNN 계층을 리스트로 저장하는 용도\n",
    "        \n",
    "        self.h, self.dh = None, None ## h는 forward()불렀을 때 마지막 RNN 계층의 은닉 상태를 저장, \n",
    "                                      ## dh는 backward()불렀을 때 하나 앞 블록의 은닉 상태의 기울기 저장\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "    \n",
    "    \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params \n",
    "        N, T, D = xs.shape ## 미니배치 크기 N, 입력벡터 차원 D, T개 분량의 시계열 데이터\n",
    "        D, H = Wx.shape \n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype = 'f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:  ## (Not a) OR ( b )  --> 은닉상태를 이어 받는 경우 h를 영행렬로 초기화\n",
    "            self.h = np.zeros((N, H), dtype = 'f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "\n",
    "    \n",
    "    def backward(self,dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype = 'f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        \n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh) ## 합산된 기울기\n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "            \n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 시계열 데이터 처리 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이번 장의 목표는 RNN을 사용하여 '언어 모델'을 구현하는 것이다. \n",
    "## 여기서는 RNN 계층을 수직방향으로 몇 개 더 쌓아볼 것이다.\n",
    "## 또 RNN을 사용한 언어 모델은 RNN Language Model 이므로 RNNLM이라고 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 전체 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## w(t) --> Embedding --> RNN --> Affine --> Softmax --> y(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 입력 데이터는 단어 ID 배열이다.\n",
    "## 첫 단어로 ID가 0인 'you'가 입력된다. softmax 계층이 출력하는 확률분포를 보면 'say'에서 가장 높게 나온다.\n",
    "## 이처럼 제대로 예측하려면 좋은 가중치(잘 학습된 가중치)를 사용해야한다.\n",
    "## 두 번째 단어인 'say'를 입력하면 'goodbye'와 'hello'에서 높게 나온다. \n",
    "## 여기서 주목할 것은 RNN 계층은 'you say'라는 맥락을 기억하고 있다.\n",
    "## 즉, RNN은 'you say'라는 과거의 정보를 응집된 은닉상태 벡터로 저장해놓고 있다.\n",
    "## RNNLM은 지금까지 입력된 단어를 기억하고 그것을 바탕으로 다음에 출현할 단어를 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T개 분의 시계열 데이터를 한 번에 처리하는 계층을 Time XX 계층이라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # 배치용과 시계열용을 정리(reshape)\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNNLM에서 사용하는 신경망을 SimpleRnnlm이라는 이름의 클래스로 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')       ## 표준편차 0.01 분포 초깃값\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') ## Xavier 초깃값\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f') ## Xavier 초깃값\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f') ## Xavier 초깃값\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful = True), ## Truncated BPTT 학습이라 가정하여 stateful = True 설정\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout = 1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()  ## 신경망의 상태를 초기화하는 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언어 모델의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 언어 모델은 주어진 과거 단어로부터 다음에 출현할 단어의 확률분포를 출력한다.\n",
    "## 이때 언어 모델의 예측 성능을 평가하는 척도로 퍼플렉서티(Perplexity, 혼란도)를 자주 이용한다.\n",
    "## 퍼플렉서티는 간단히 말하면 확률의 역수이다. \n",
    "## 모델 1에 you라는 단어를 주니 say의 확률이 0.8로 나왔고 정답도 say라면 퍼플렉서티는 1 / 0.8 = 1.25이다.\n",
    "## 모델 2에 you라는 단어를 주니 say의 확률이 0.2로 나왔다. 이 때 퍼플렉서티는 1 / 0.2 = 5\n",
    "## 따라서 퍼플렉서티는 낮을수록 좋다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 퍼플렉서티는 직관적으로 분기 수(number of bunches)로 해석할 수 있다.\n",
    "## 분기 수란 다음에 취할 수 있는 선택사항의 수를 의미하는데, 분기 수가 1.25라는 것은 다음에 출현할 수 있는 단어 후보를\n",
    "## 1개로 좁혔다는 뜻이다. 반면 5일때는 단어 후보가 5개나 남았다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 입력 데이터(단어)가 여러 개일 때는 L = - 1/N sum(sum(tlogy))\n",
    "## Perplexity = exp(L)로 계산한다.\n",
    "## N은 데이터 총 개수이고, t는 원핫 벡터로 나타낸 정답 레이블, y는 확률분포를 나타낸다.\n",
    "## 정리하면 퍼플렉서티가 작아질수록 분기수가 줄어 좋은 모델이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이제 위에서 구현한 신경망에 데이터를 주고 학습을 수행해보자\n",
    "## PTB 데이터 셋을 이용하는데, 이번에 사용할 RNNLM은 전부 다 사용하면 좋은 결과를 얻기 힘들기 때문에\n",
    "## 처음 1000개 단어만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 412.32\n",
      "| 에폭 2 | 퍼플렉서티 327.29\n",
      "| 에폭 3 | 퍼플렉서티 235.56\n",
      "| 에폭 4 | 퍼플렉서티 219.29\n",
      "| 에폭 5 | 퍼플렉서티 209.33\n",
      "| 에폭 6 | 퍼플렉서티 203.33\n",
      "| 에폭 7 | 퍼플렉서티 200.07\n",
      "| 에폭 8 | 퍼플렉서티 197.48\n",
      "| 에폭 9 | 퍼플렉서티 191.97\n",
      "| 에폭 10 | 퍼플렉서티 192.56\n",
      "| 에폭 11 | 퍼플렉서티 188.31\n",
      "| 에폭 12 | 퍼플렉서티 192.78\n",
      "| 에폭 13 | 퍼플렉서티 189.26\n",
      "| 에폭 14 | 퍼플렉서티 189.60\n",
      "| 에폭 15 | 퍼플렉서티 188.94\n",
      "| 에폭 16 | 퍼플렉서티 185.95\n",
      "| 에폭 17 | 퍼플렉서티 183.40\n",
      "| 에폭 18 | 퍼플렉서티 179.13\n",
      "| 에폭 19 | 퍼플렉서티 178.99\n",
      "| 에폭 20 | 퍼플렉서티 180.48\n",
      "| 에폭 21 | 퍼플렉서티 179.54\n",
      "| 에폭 22 | 퍼플렉서티 174.08\n",
      "| 에폭 23 | 퍼플렉서티 172.84\n",
      "| 에폭 24 | 퍼플렉서티 173.82\n",
      "| 에폭 25 | 퍼플렉서티 172.20\n",
      "| 에폭 26 | 퍼플렉서티 169.71\n",
      "| 에폭 27 | 퍼플렉서티 163.28\n",
      "| 에폭 28 | 퍼플렉서티 163.29\n",
      "| 에폭 29 | 퍼플렉서티 160.63\n",
      "| 에폭 30 | 퍼플렉서티 153.49\n",
      "| 에폭 31 | 퍼플렉서티 153.71\n",
      "| 에폭 32 | 퍼플렉서티 148.26\n",
      "| 에폭 33 | 퍼플렉서티 149.47\n",
      "| 에폭 34 | 퍼플렉서티 144.25\n",
      "| 에폭 35 | 퍼플렉서티 142.35\n",
      "| 에폭 36 | 퍼플렉서티 136.80\n",
      "| 에폭 37 | 퍼플렉서티 132.92\n",
      "| 에폭 38 | 퍼플렉서티 128.33\n",
      "| 에폭 39 | 퍼플렉서티 121.67\n",
      "| 에폭 40 | 퍼플렉서티 119.69\n",
      "| 에폭 41 | 퍼플렉서티 118.36\n",
      "| 에폭 42 | 퍼플렉서티 112.54\n",
      "| 에폭 43 | 퍼플렉서티 106.90\n",
      "| 에폭 44 | 퍼플렉서티 101.65\n",
      "| 에폭 45 | 퍼플렉서티 99.55\n",
      "| 에폭 46 | 퍼플렉서티 98.30\n",
      "| 에폭 47 | 퍼플렉서티 92.16\n",
      "| 에폭 48 | 퍼플렉서티 87.86\n",
      "| 에폭 49 | 퍼플렉서티 83.37\n",
      "| 에폭 50 | 퍼플렉서티 79.59\n",
      "| 에폭 51 | 퍼플렉서티 75.10\n",
      "| 에폭 52 | 퍼플렉서티 71.68\n",
      "| 에폭 53 | 퍼플렉서티 68.09\n",
      "| 에폭 54 | 퍼플렉서티 65.36\n",
      "| 에폭 55 | 퍼플렉서티 61.97\n",
      "| 에폭 56 | 퍼플렉서티 58.58\n",
      "| 에폭 57 | 퍼플렉서티 55.67\n",
      "| 에폭 58 | 퍼플렉서티 51.95\n",
      "| 에폭 59 | 퍼플렉서티 48.30\n",
      "| 에폭 60 | 퍼플렉서티 46.14\n",
      "| 에폭 61 | 퍼플렉서티 44.33\n",
      "| 에폭 62 | 퍼플렉서티 41.95\n",
      "| 에폭 63 | 퍼플렉서티 37.38\n",
      "| 에폭 64 | 퍼플렉서티 36.71\n",
      "| 에폭 65 | 퍼플렉서티 35.07\n",
      "| 에폭 66 | 퍼플렉서티 33.00\n",
      "| 에폭 67 | 퍼플렉서티 30.84\n",
      "| 에폭 68 | 퍼플렉서티 28.67\n",
      "| 에폭 69 | 퍼플렉서티 27.44\n",
      "| 에폭 70 | 퍼플렉서티 26.13\n",
      "| 에폭 71 | 퍼플렉서티 24.48\n",
      "| 에폭 72 | 퍼플렉서티 23.86\n",
      "| 에폭 73 | 퍼플렉서티 22.63\n",
      "| 에폭 74 | 퍼플렉서티 20.98\n",
      "| 에폭 75 | 퍼플렉서티 20.33\n",
      "| 에폭 76 | 퍼플렉서티 18.31\n",
      "| 에폭 77 | 퍼플렉서티 17.56\n",
      "| 에폭 78 | 퍼플렉서티 16.81\n",
      "| 에폭 79 | 퍼플렉서티 16.08\n",
      "| 에폭 80 | 퍼플렉서티 14.40\n",
      "| 에폭 81 | 퍼플렉서티 14.15\n",
      "| 에폭 82 | 퍼플렉서티 13.73\n",
      "| 에폭 83 | 퍼플렉서티 12.62\n",
      "| 에폭 84 | 퍼플렉서티 12.18\n",
      "| 에폭 85 | 퍼플렉서티 11.36\n",
      "| 에폭 86 | 퍼플렉서티 11.18\n",
      "| 에폭 87 | 퍼플렉서티 10.46\n",
      "| 에폭 88 | 퍼플렉서티 9.71\n",
      "| 에폭 89 | 퍼플렉서티 9.30\n",
      "| 에폭 90 | 퍼플렉서티 9.19\n",
      "| 에폭 91 | 퍼플렉서티 8.78\n",
      "| 에폭 92 | 퍼플렉서티 8.17\n",
      "| 에폭 93 | 퍼플렉서티 7.90\n",
      "| 에폭 94 | 퍼플렉서티 7.22\n",
      "| 에폭 95 | 퍼플렉서티 6.95\n",
      "| 에폭 96 | 퍼플렉서티 6.81\n",
      "| 에폭 97 | 퍼플렉서티 6.81\n",
      "| 에폭 98 | 퍼플렉서티 6.15\n",
      "| 에폭 99 | 퍼플렉서티 6.10\n",
      "| 에폭 100 | 퍼플렉서티 5.61\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from ch05.simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 현재의 모델로는 큰 말뭉치에는 전혀 대응할 수 없다. 이런 문제는 다음 장에서 개선한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 방금의 학습을 수행하는 RnnlmTrainer 클래스를 제공\n",
    "## 이 클래스는 방금 수행한 RNNLM 학습을 클래스 안으로 숨겨준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 417.93\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 353.88\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 248.56\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 217.86\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 209.83\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 208.10\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.56\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.17\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 195.02\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 190.87\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.52\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.48\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.86\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.29\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 186.96\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.19\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.34\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 184.66\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.16\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.58\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.03\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.09\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 180.76\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 177.41\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.76\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 173.66\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 169.35\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.17\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 166.75\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 160.94\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 157.99\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 153.23\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 152.71\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 150.07\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 145.42\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 141.32\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 142.00\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 132.21\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 129.97\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 124.50\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 120.13\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 119.87\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 113.55\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 108.42\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 103.00\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 100.13\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 96.89\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 92.60\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 89.24\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 84.66\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 81.92\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 76.04\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 74.40\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 70.05\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 66.33\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 63.65\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 62.90\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 57.52\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 54.43\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 51.33\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 47.45\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 44.83\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 43.87\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 40.59\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 37.59\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 36.14\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 33.98\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 31.85\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 30.77\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 28.93\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 27.17\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 25.52\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 24.73\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 23.39\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 21.88\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 21.04\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 19.48\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 18.17\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 17.63\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 16.86\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 15.68\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.72\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.24\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.29\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.08\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 12.02\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 11.66\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.65\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.73\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.46\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 9.59\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 9.20\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.87\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.43\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.08\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.79\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.55\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.25\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.45\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\LoteeYoon\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from ch05.simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
